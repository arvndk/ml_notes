## Thomas L4 - Probabilistic Graphical Models and Structured Domains

-  Probabilistic models (syntax and semantics)
-  Temporal models (Hidden Markov models)
-  Plate notation
-  Learning in structured models
-  Bayesian learning

A **probabilistic model** is typically learned from data using **statistical learning techniques**. They typically apply **Probabilistic inference** algorithms to use models for prediction or structure analysis. **Probabilitis inference** is the task of deriving the probability of one or more random variables taking a specific cvalue or set of values.

 Now a **Probabilistic Graphical Model** are a type of graphical model that is used to model the dynamics of a system:
- supports a structured specification of high-dimensional distributions in terms of low-dimensional factors
- its structured representation can be exploited for efficient learning and inference algorithms (sometimes ...)
- its graphical representation gives a human-friendly design and description possibilities

A probabilistic graphical model two different types of variables these are: 
- **State variables:** variables that are used to describe the state of the system at each point in time.
- **Observation variables:** describe what can be observed from the system at each point in time.

Some Advantages of probabilistic methods:
- Principled quantification of prediction uncertainties
- Robust and principled techniques to deal with incomplete information, missing data. 
- Provides a general model of the domain that can in principle be used to answer any inference query.
- Enables integration of domain knowledge. 
- Transparent and explainable.
### Bayesian Networks

**Syntax:** Bayesian network is a collection of variables, say $X1...Xn$, that has a graphical component, **a directed acyclic graph** $G = {V, E}$ where the nodes correspond to the variables $X1,..., Xn$. We have a set of local conditional distributions, one for each variable in the network, where we have the probability of that variable conditioned in it's parents: $P = {p(Xi | pa(Xi)), Xi \epsilon V}$ where $pa(Xi)$ are the parents of $Xi$ in $G$ as defined by the edges $E$. 

**Semantics:** We have bayesian network over a collection of nodes $X1,..., Xn$ specify a join probability distribution given by the multiplication of conditional probabibility distributions that goes into the specification of the model. 
$pN(X1,...Xn) = \Pi_{i=1}^n.p(Xi | pa(Xi))$ 

**Inference:** Given a bayesian network model, and some evidence, we can do inference on it. 
$p(X = x, G = g) = \frac{p(X = x, G = g)}{p(g)}$ Probability of X, given G = g. It's done by finding the probability of two variables of interest $X$ and $G$, and dividing with probability of component that we are conditioning on, $G$ in this case. 

The maximum likelihood learning is probabilistic approach to determine values fro parameters of a model. The goal is to find the parameters that maximize the likelihood of the data. To sum up maximum likelihood learning is A technic to find the parameters that maximize the likelihood of the data. 

The maximum likelihood learning is probabilistic approach to determine values fro parameters of a model. The goal is to find the parameters that maximize the likelihood of the data. To sum up maximum likelihood learning is A technic to find the parameters that maximize the likelihood of the data. 

Now to the **EM algorithm**. EM is a way to find the maximum likelihood parameters of a model. EM is a iterative algorithm that is used to find the maximum likelihood parameters of a model.

The EM algorithm generally works consists of the following steps:
I. Initialization of the parameters of the model.
II. Expectation step, where the model is estimated based on the data.
III. Maximization step, where the model is updated based on the estimated parameters.

An example of dynamic, temporal graphical models is the **hidden markov model**. **Hidden markov models** are a type of probabilistic graphical model that is used to model the temporal dynamics of a system.
They are used to model the dynamics of a system, with the assumption that the probability of a state is directly related to the probability of the previous state.
In hidden markov models we cannot observe the stats themselves, but only the results from the observations. What we try to estimate is the probability of the system being in a certain state. The probability of the hidden states is essentially what we try to estimate in the hidden markov model. This helps to describe the dynamics of the system.

A hidden markov model consist of an Markov Chain(which is hidden) and two different types of variables these are:
- State variables, these are the variables that are used to describe the state of the system at each point in time.
- Observation variables, these these describe what can be observed from the system at each point in time.

Emission matrix: The sensor model specifies the probability of detection by each given the state. Example this tells us what the probability of someone having a umbrella when the state is rain.
Transition matrix: The transition matrix specifies the probability of transitioning between the different states.

**To summarize hidden markov models are a type of probabilistic graphical model that is used to model the temporal dynamics of a system, without knowing the state of the system.**

In **Bayesian inference** **plate notation** is a method of representing variables that reapeat in a graphical model. Instead of drawing each repreated variable individually, a plate or rectangle is used to group variables into a subngraph that repeat together and number is drawn on the plate to represent the number of repititions of the subgraph in the plate.

<img src="..\..\attachments\plate.png" width="500px">

**Bayesian Learning** is a probabilistic method to determine the parameters of a model. This is done by having a **prior distribution** over the parameters of the model. **A prior probability distribution**, often simply called the prior, of an uncertain quantity is the probability distribution that would express one's beliefs about this quantity before some evidence is taken into account. Using bayes rule we then combine the prior distribution with the likelihood of the data. This gives us the posterior distribution over the parameters of the model. **Posterior probability** is the probability an event will happen after all evidence or background information has been taken into account. In bayesian learning we treat the parameters of the model as the latent variables, meaning that the parameters are not directly known to the user.  **Bayesian learning is an example of static graphical models**. **Thus we work under the assumption that the parameters are independent of each other.**

 - Parameters are modeled as random variables and infromation about them can be included prior to observing the data. (This would allow type of smoothing with pseudo-count. Also, it allows us to include prior knowledge about the values the params should have.)
 - By baye's rule, the prior info is combined with likelihood, yielding a posterior distribution that is used for making inferences about the parameter and not just inferences about variables in the model. 

For data $D = (X1,...,Xn)$
Bayes Formula:
$$p(\theta|D) = \frac{p(D|\theta).p(\theta)}{p(D)}$$

- $p(\theta|D)$: Posterior probability of theta, given the data D.
- $\theta$: Network weights or parameters.
- $D$: Dataset. 
- $p(\theta)$: Prior distribution or prior probabilities over network weights. 
- $p(D|\theta)$: Likelihood function.
