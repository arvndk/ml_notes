## Thomas L5 - Variational Inference in Probabilistic Models

-   Probabilistic models and plate notation
-   Variational inference basics (objective function, Evidence lower bound, mean field assumption)   
-   Black-box variational inference
-   Variational inference and probabilistic programming

A **probabilistic model** is typically learned from data using **statistical learning techniques**. They typically apply **Probabilistic inference** algorithms to use models for prediction or structure analysis. **Probabilitis inference** is the task of deriving the probability of one or more random variables taking a specific cvalue or set of values.

 Now a **Probabilistic Graphical Model** are a type of graphical model that is used to model the dynamics of a system:
- supports a structured specification of high-dimensional distributions in terms of low-dimensional factors
- its structured representation can be exploited for efficient learning and inference algorithms (sometimes ...)
- its graphical representation gives a human-friendly design and description possibilities

A probabilistic graphical model two different types of variables these are: 
- **State variables:** variables that are used to describe the state of the system at each point in time.
- **Observation variables:** describe what can be observed from the system at each point in time.

Some Advantages of probabilistic methods:
- Principled quantification of prediction uncertainties
- Robust and principled techniques to deal with incomplete information, missing data. 
- Provides a general model of the domain that can in principle be used to answer any inference query.
- Enables integration of domain knowledge. 
- Transparent and explainable.

In **Bayesian inference** **plate notation** is a method of representing variables that reapeat in a graphical model. Instead of drawing each repreated variable individually, a plate or rectangle is used to group variables into a subngraph that repeat together and number is drawn on the plate to represent the number of repititions of the subgraph in the plate.

<img src="..\..\attachments\plate.png" width="500px">

**Variational inference** is a method for approximating  distributions. The main idea of variational inference is essentially to cast inference as a optimization problem as a minimization problem. 

The main idea of variational methods is to cast inference as an optimization problem. 

Variational Bayesian methods are a family of **techniques for approximating uncontrollable integrals arising in Bayesian inference** and machine learning. They are typically used in complex statistical models consisting of observed variables (usually termed "data") as well as unknown parameters and latent variables, with various sorts of relationships among the three types of random variables, as might be described by a graphical model. As typical in Bayesian inference, the parameters and latent variables are grouped together as "unobserved variables". Variational Bayesian methods are primarily used for two purposes:

1. To provide an analytical approximation to the posterior probability of the unobserved variables, in order to do statistical inference over these variables.
2. To derive a lower bound for the marginal likelihood (sometimes called the evidence) of the observed data (i.e. the marginal probability of the data given the model, with marginalization performed over unobserved variables). This is typically used for performing model selection, the general idea being that a higher marginal likelihood for a given model indicates a better fit of the data by that model and hence a greater probability that the model in question was the one that generated the data.

In the former purpose (that of approximating a posterior probability), variational Bayes is an alternative to Monte Carlo sampling methods — particularly, Markov chain Monte Carlo methods such as Gibbs sampling — for taking a fully Bayesian approach to statistical inference over complex distributions that are difficult to evaluate directly or sample. In particular, whereas Monte Carlo techniques provide a numerical approximation to the exact posterior using a set of samples, variational Bayes provides a locally-optimal, exact analytical solution to an approximation of the posterior. 

VI is deterministic, ie, there is no randomness. VI has easy to gauge convergence. 

Variational inference has some main differences from sampling based inference such as Gibbs sampling.
- Almost never find the globally optimal solution
- We know when they converge
- Usually they scale better than sampling
**To summarize then variational inference is used to compute the posterior distribution of a model.**

**A objective function** is in machine learning a function the you would like to maximize or minimize. In machine learning this is the function that is used to optimize the model. Essentially the objective function is the **cost function**.

 Very often in Probability and Statistics we'll replace observed data or a complex distributions with a simpler, approximating distribution. **KL Divergence** for example helps us to measure just how much information we lose when we choose an approximation.

Now I'll talk about the **evidence lower bound**. To do this I think is important to understand what evidence means in the this context. **Essentially the evidence are the likelihood of the data given the model**. Thus the **evidence lower bound is simply the lower bound of the evidence**. This is useful because it is a way to estimate the quality of the model, since a higher evidence may indicate that we have chosen the right model. Essentially we want to maximize the evidence lower bound, which indigently means minimizing the KL divergence. Because of this we can say than we try to maximize the log likelihood and minimize the distance to the prior.The **Penalty term** penalizes large deviations between the sample and prior. 

Quickly I will explain why we want to minimize KL-divergence it is because KL-divergence is a measure of how much to distribution from each other.

The mean field assumption is a assumption that we do about the variational distribution. That is, we assume that each weight in the neural network is independent of all the others.

In **black box variation** they instead use **stochastic optimization** to maximize the **ELBO**. In **stochastic optimization**, we maximize a function using noisy estimates of its gradient.

Black-Box Variational Inference promises VB inference in any model, but at the cost that inference relies on sampling – and it sometimes shows poor converge properties in practice.

Probabilistic Programming Languages are languages to describe probabilistic models and perform inference in them. **Pyro** is a PPL built on top of PyTorch, and which supports several inference techniques, including BBVI, SVI, MCMC. Several other alternatives exist as well (Edward, Stan, JAGS, InferPy . . . ).

In the self study we used bayesian linear regression.
In doing this i will attempt to explain how it works and the process of doing it.

In bayesian linear regression we try to find the best posterior distribution of the parameters of the model.
In this cell we initialize the prior distributions in the next cell we specify the variational distribution.

Now we use these to actually learn the model.
Firstly we generate some data for the model.
then we initializes a instance of evidence lower bound.
These are then used to initialize the model.
now we simply take steps by using the generated data and prints some evaluation metrics out during learning.
When the training is done we plot the result. Where we have the original data and the learned distribution.

In the experiment we did the learning again but this time making subtle changes to the parameters used to observe the effect.
For the first set of experiments we changed the number of samples in the data and the precision of the sensor.

More samples seems to generally benefit the model. 
A low sensor quality resulted in a higher error in the model. But doubling the sensor quality did not double the the performance of the model.
Thus there is a non-linear relationship between the performance and the sensor quality.

For the next experiment we tried to change the learning rate and the confidence in the prior.
Learning rate seems to not really effect the result much in this case.

Moving the prior away from the true model also seemed to have little effect on the model.

finally increasing the confidence in the wrong guide seems to have a little effect on the model.

for the final experiment we tried to change confidence in the prior and change the prior distribution.

Increasing confidence in prior seems to be detrimental to the model,
but changing the prior distribution seems to have little actual effect.
